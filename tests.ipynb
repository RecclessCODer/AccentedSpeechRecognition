{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'20-02-2019_19h15m36'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 1\n",
    "%aimport config\n",
    "\n",
    "conf = config.Config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import MultiTask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MultiTask.load_model('saved_models/test.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultiTask(\n",
       "  (Head): Head(\n",
       "    (conv): MaskConv(\n",
       "      (seq_module): Sequential(\n",
       "        (0): Conv2d(1, 32, kernel_size=(41, 11), stride=(2, 2), padding=(20, 5))\n",
       "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): Hardtanh(min_val=0, max_val=20, inplace)\n",
       "        (3): Conv2d(32, 32, kernel_size=(21, 11), stride=(2, 1), padding=(10, 5))\n",
       "        (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): Hardtanh(min_val=0, max_val=20, inplace)\n",
       "      )\n",
       "    )\n",
       "    (rnns): Sequential(\n",
       "      (0): BatchRNN(\n",
       "        (rnn): GRU(1120, 800, bidirectional=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (SpeechToText): SpeechToText(\n",
       "    (rnns): Sequential(\n",
       "      (0): BatchRNN(\n",
       "        (rnn): GRU(800, 800, bidirectional=True)\n",
       "      )\n",
       "    )\n",
       "    (fc): Sequential(\n",
       "      (0): SequenceWise (\n",
       "      Sequential(\n",
       "        (0): BatchNorm1d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): Linear(in_features=800, out_features=29, bias=False)\n",
       "      ))\n",
       "    )\n",
       "    (inference_softmax): InferenceBatchSoftmax()\n",
       "  )\n",
       "  (AccentClassifier): AccentClassifier(\n",
       "    (rnns): Sequential(\n",
       "      (0): BatchRNN(\n",
       "        (rnn): GRU(800, 800, bidirectional=True)\n",
       "      )\n",
       "    )\n",
       "    (bnf): Sequential(\n",
       "      (0): BatchNorm1d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (1): Linear(in_features=800, out_features=1024, bias=True)\n",
       "      (2): ReLU()\n",
       "      (3): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (4): Linear(in_features=1024, out_features=256, bias=True)\n",
       "      (5): ReLU()\n",
       "    )\n",
       "    (fc): Sequential(\n",
       "      (0): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (1): Linear(in_features=256, out_features=4, bias=True)\n",
       "      (2): ReLU()\n",
       "    )\n",
       "    (softmax): Softmax()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'use_mfcc_in': True,\n",
       " 'use_ivectors_in': False,\n",
       " 'use_embeddings_in': True,\n",
       " 'use_transcripts_out': True,\n",
       " 'use_accents_out': True,\n",
       " 'mfcc_size': 40,\n",
       " 'ivector_size': 100,\n",
       " 'embedding_size': 100,\n",
       " 'rnn_type': torch.nn.modules.rnn.GRU,\n",
       " 'labels': \"_'ABCDEFGHIJKLMNOPQRSTUVWXYZ \",\n",
       " 'accents_dict': {'australia': 0, 'canada': 1, 'england': 2, 'us': 3},\n",
       " 'rnn_hidden_size': 800,\n",
       " 'nb_head_layers': 1,\n",
       " 'nb_speech_layers': 1,\n",
       " 'nb_accents_layers': 1,\n",
       " 'bidirectional': True,\n",
       " 'bottleneck_size': 256,\n",
       " 'DEBUG': False}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model._meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'epochs': [1], 'labels': [\"_'ABCDEFGHIJKLMNOPQRSTUVWXYZ \"], 'batch_size': [20], 'num_workers': [4], 'cuda': [True], 'losses_mix': [0.9], 'learning_rate': [0.0003], 'mfcc_size': [40], 'ivector_size': [100], 'embedding_size': [100], 'rnn_type': [<class 'torch.nn.modules.rnn.GRU'>], 'rnn_hidden_size': [800], 'nb_head_layers': [1], 'nb_speech_layers': [1], 'nb_accents_layers': [1], 'bidirectional': [True], 'bottleneck_size': [256], 'use_mfcc_in': [True], 'use_ivectors_in': [False], 'use_embeddings_in': [True], 'use_transcripts_out': [True], 'use_accents_out': [True], 'decoder_alpha': [0.8], 'decoder_beta': [1.0], 'decoder_cutoff_top_n': [40], 'decoder_cutoff_prob': [1.0], 'decoder_beam_width': [100], 'lm_path': ['./data/language_models/cv.lm'], 'train_manifest': ['./data/splits/dev.csv'], 'test_manifest': ['./data/splits/test.csv'], 'tensorboard_path': ['./tensorboard_runs/'], 'saved_models_path': ['./saved_models/']}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20, 732, 140])\n"
     ]
    }
   ],
   "source": [
    "from dataloader import MultiDataset, MultiDataLoader\n",
    "import torch\n",
    "\n",
    "labels = \" 'ABCDEFGHIJKLMNOPQRSTUVWXYZ_\"\n",
    "\n",
    "\n",
    "dataset = MultiDataset('data/splits/dev.csv', labels, \n",
    "                       use_mfcc_in=model._meta['use_mfcc_in'], \n",
    "                       use_ivectors_in=model._meta['use_ivectors_in'], \n",
    "                       use_embeddings_in=model._meta['use_embeddings_in'],\n",
    "                       use_transcripts_out=model._meta['use_transcripts_out'], \n",
    "                       use_accents_out=model._meta['use_accents_out'])\n",
    "\n",
    "dataloader = MultiDataLoader(dataset, batch_size=20, shuffle=True)\n",
    "\n",
    "for data in dataloader:\n",
    "    print(data[0].size())\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import MultiTask\n",
    "\n",
    "model = MultiTask(DEBUG=False, rnn_hidden_size=800, \n",
    "                  use_mfcc_in=conf['use_mfcc_in'], \n",
    "                  use_ivectors_in=conf['use_ivectors_in'], \n",
    "                  use_embeddings_in=conf['use_embeddings_in'],\n",
    "                  use_transcripts_out=conf['use_transcripts_out'], \n",
    "                  use_accents_out=conf['use_accents_out'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "blib \n",
      "\n",
      "test\n"
     ]
    }
   ],
   "source": [
    "print('blib', '\\n')\n",
    "print('test')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'australia': 0, 'canada': 1, 'england': 2, 'us': 3}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.accent_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[True]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conf['use_embeddings_in']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model._meta['use_embeddings_in']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3351a1c54734de0b6fe48058fa7e33e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=58), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "model = model.cuda()\n",
    "\n",
    "for data in tqdm(dataloader):\n",
    "    inputs, inputs_lens, transcripts, transcripts_lens, accents = data\n",
    "\n",
    "    \n",
    "    a, b, c, __ = model(inputs.cuda(), inputs_lens.cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "MultiTask.serialize(model, 'tmp')\n",
    "\n",
    "modelb = MultiTask.load_model('tmp')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelb = modelb.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8850c82f6c9d4458bc727af18e20630b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=571), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for data in tqdm(dataloader):\n",
    "    inputs, inputs_lens, transcripts, transcripts_lens, accents = data\n",
    "\n",
    "    \n",
    "    a, b, c = modelb(inputs.cuda(), inputs_lens.cuda())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@classmethod\n",
    "def load_model(cls, path):\n",
    "    package = torch.load(path, map_location=lambda storage, loc: storage)\n",
    "    model = cls(rnn_hidden_size=package['hidden_size'], nb_layers=package['nb_layers'],\n",
    "                labels=package['labels'], audio_conf=package['audio_conf'],\n",
    "                rnn_type=supported_rnns[package['rnn_type']], bidirectional=package.get('bidirectional', True))\n",
    "    model.load_state_dict(package['state_dict'])\n",
    "    for x in model.rnns:\n",
    "        x.flatten_parameters()\n",
    "    return model\n",
    "\n",
    "@classmethod\n",
    "def load_model_package(cls, package):\n",
    "    model = cls(rnn_hidden_size=package['hidden_size'], nb_layers=package['nb_layers'],\n",
    "                labels=package['labels'], audio_conf=package['audio_conf'],\n",
    "                rnn_type=supported_rnns[package['rnn_type']], bidirectional=package.get('bidirectional', True))\n",
    "    model.load_state_dict(package['state_dict'])\n",
    "    return model\n",
    "\n",
    "@staticmethod\n",
    "def serialize(model, optimizer=None, epoch=None, iteration=None, loss_results=None,\n",
    "              main_loss_results=None, side_loss_results=None,\n",
    "              cer_results=None, wer_results=None, mca_results=None, avg_loss=None, meta=None):\n",
    "    model = model.module if DeepSpeech.is_parallel(model) else model\n",
    "    package = {\n",
    "        'version': model._version,\n",
    "        'hidden_size': model._hidden_size,\n",
    "        'nb_layers': model._nb_layers,\n",
    "        'rnn_type': supported_rnns_inv.get(model._rnn_type, model._rnn_type.__name__.lower()),\n",
    "        'audio_conf': model._audio_conf,\n",
    "        'labels': model._labels,\n",
    "        'state_dict': model.state_dict(),\n",
    "        'bidirectional': model._bidirectional\n",
    "    }\n",
    "    if optimizer is not None:\n",
    "        package['optim_dict'] = optimizer.state_dict()\n",
    "    if avg_loss is not None:\n",
    "        package['avg_loss'] = avg_loss\n",
    "    if epoch is not None:\n",
    "        package['epoch'] = epoch + 1  # increment for readability\n",
    "    if iteration is not None:\n",
    "        package['iteration'] = iteration\n",
    "    if loss_results is not None:\n",
    "        package['loss_results'] = loss_results\n",
    "        package['main_loss_results'] = main_loss_results\n",
    "        package['side_loss_results'] = side_loss_results\n",
    "        package['cer_results'] = cer_results\n",
    "        package['wer_results'] = wer_results\n",
    "        package['mca_results'] = mca_results\n",
    "    if meta is not None:\n",
    "        package['meta'] = meta\n",
    "    return package"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
